# -*- coding: utf-8 -*-
"""Agedetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l0_nVZbRuRUVew7lOMPnxLA7KTCYGwpo
"""

# import tarfile
# fname = "/content/drive/My Drive/Agedetection/wiki_crop.tar"
# if (fname.endswith("tar.gz")):
#     tar = tarfile.open(fname, "r:gz")
#     tar.extractall("/content/drive/My Drive/Agedetection/")
#     tar.close()
# elif (fname.endswith("tar")):
#     tar = tarfile.open(fname, "r:")
#     tar.extractall("/content/drive/My Drive/Agedetection/")
#     tar.close()

import scipy.io
import numpy as np
import pandas as pd
from datetime import datetime, timedelta

import tensorflow as tf

import keras
from keras.preprocessing import image
from keras.callbacks import ModelCheckpoint,EarlyStopping
from keras.layers import Dense, Activation, Dropout, Flatten, Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Activation
from keras.layers import Conv2D, AveragePooling2D
from keras.models import Model, Sequential

from sklearn.model_selection import train_test_split

from keras import metrics

from keras.models import model_from_json
import matplotlib.pyplot as plt





from datetime import datetime, timedelta

import scipy.io
mat = scipy.io.loadmat('/content/drive/My Drive/Agedetection/wiki_crop/wiki.mat')



instances = mat['wiki'][0][0][0].shape[1]
 
columns = ["dob", "photo_taken", "full_path", "gender", "name", "face_location", "face_score", "second_face_score"]
 
import pandas as pd
df = pd.DataFrame(index = range(0,instances), columns = columns)
 
for i in mat:
    if i == "wiki":
        current_array = mat[i][0][0]
        for j in range(len(current_array)):
            #print(columns[j],": ",current_array[j])
            df[columns[j]] = pd.DataFrame(current_array[j][0])
            
# df.head()




def datenum_to_datetime(datenum):
    """
    Convert Matlab datenum into Python datetime.
    :param datenum: Date in datenum format
    :return:        Datetime object corresponding to datenum.
    """
    days = datenum % 1
    hours = days % 1 * 24
    minutes = hours % 1 * 60
    seconds = minutes % 1 * 60
    exact_date = datetime.fromordinal(int(datenum)) \
           + timedelta(days=int(days)) \
           + timedelta(hours=int(hours)) \
           + timedelta(minutes=int(minutes)) \
           + timedelta(seconds=round(seconds)) \
           - timedelta(days=366)
    
    return exact_date.year
  
  
df['date_of_birth'] = df['dob'].apply(datenum_to_datetime)

df['age'] = df['photo_taken'] - df['date_of_birth']


df = df[df['face_score'] != -np.inf]

df = df[df['second_face_score'].isna()]


df = df[df['face_score'] >= 3]

df = df.drop(columns = ['name','face_score','second_face_score','date_of_birth','face_location'])


df = df[df['age'] <= 100]


df = df[df['age'] > 0]
df = df.iloc[20000:]
# df

classes = 101 #(0, 100])
print("number of output classes: ",classes)

target_size = (224, 224)

def getImagePixels(image_path):
    img = image.load_img("/content/drive/My Drive/Agedetection/wiki_crop/%s" % image_path[0], grayscale=False, target_size=target_size)
    x = image.img_to_array(img).reshape(1, -1)[0]
    #x = preprocess_input(x)
    return x

df['pixels'] = df['full_path'].apply(getImagePixels)


target = df['age'].values
target_classes = keras.utils.to_categorical(target, classes)


features = []

for i in range(0, df.shape[0]):
    features.append(df['pixels'].values[i])

features = np.array(features)
features = features.reshape(features.shape[0], 224, 224, 3)
features.shape

features /= 255 #normalize in [0, 1]

train_x, test_x, train_y, test_y = train_test_split(features, target_classes
                                        , test_size=0.30)#, random_state=42), stratify=target_classes)






#VGG-Face model
model = Sequential()
model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))
model.add(Convolution2D(64, (3, 3), activation='relu'))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2,2), strides=(2,2)))
 
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(128, (3, 3), activation='relu'))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2,2), strides=(2,2)))
 
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(256, (3, 3), activation='relu'))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(256, (3, 3), activation='relu'))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(256, (3, 3), activation='relu'))
model.add(MaxPooling2D((2,2), strides=(2,2)))
 
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(512, (3, 3), activation='relu'))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(512, (3, 3), activation='relu'))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(512, (3, 3), activation='relu'))
model.add(MaxPooling2D((2,2), strides=(2,2)))
 
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(512, (3, 3), activation='relu'))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(512, (3, 3), activation='relu'))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(512, (3, 3), activation='relu'))
model.add(MaxPooling2D((2,2), strides=(2,2)))
 
model.add(Convolution2D(4096, (7, 7), activation='relu'))
model.add(Dropout(0.5))
model.add(Convolution2D(4096, (1, 1), activation='relu'))
model.add(Dropout(0.5))
model.add(Convolution2D(2622, (1, 1)))
model.add(Flatten())
model.add(Activation('softmax'))
model.load_weights('/content/drive/My Drive/Agedetection/vgg_face_weights.h5')




#freeze all layers of VGG-Face except last 7 one
for layer in model.layers[:-7]:
    layer.trainable = False

base_model_output = Sequential()
base_model_output = Convolution2D(classes, (1, 1), name='predictions')(model.layers[-4].output)
base_model_output = Flatten()(base_model_output)
base_model_output = Activation('softmax')(base_model_output)

age_model = Model(inputs=model.input, outputs=base_model_output)


age_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy'])
 
checkpointer = ModelCheckpoint(filepath='/content/drive/My Drive/Agedetection/age_model.hdf5', monitor = "val_loss", verbose=1, save_best_only=True, mode = 'auto')
 
scores = []
epochs = 250; batch_size = 256
 
for i in range(epochs):
  print("epoch ",i)

  ix_train = np.random.choice(train_x.shape[0], size=batch_size)

  score = age_model.fit(train_x[ix_train], train_y[ix_train]
  , epochs=1, validation_data=(test_x, test_y), callbacks=[checkpointer])

  scores.append(score)

age_model.evaluate(test_x, test_y, verbose=1)

from google.colab import drive
drive.mount('/content/drive')

import cv2 

from google.colab.patches import cv2_imshow
face_cascade = cv2.CascadeClassifier("/content/drive/My Drive/Agedetection/haarcascade_frontalface_default.xml") 
output_indexes = np.array([i for i in range(0, 101)])
apparent_predictions = np.sum(predictions * output_indexes, axis = 1)

filepath = "/content/drive/My Drive/Agedetection/wiki_crop/58/1005258_1960-01-10_2013.jpg"
img = cv2.imread(filepath)
#filepath = "/content/drive/My Drive/Agedetection/wiki_crop/00/10049200_1891-09-16_1958.jpg"
test_img = image.load_img(filepath, target_size=(224, 224))
test_img = image.img_to_array(test_img)
test_img = np.expand_dims(test_img, axis = 0)
test_img = test_img/255
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
faces = face_cascade.detectMultiScale(gray, 1.3, 5)
prediction = age_model.predict(test_img)
apparent_age = np.round(np.sum(prediction * output_indexes, axis = 1))
if apparent_age <=18:
    name = "child"
    print("child")
elif 18 <= apparent_age <= 30:
    name = "young_adult"

    print("young_adult")
elif 30 <= apparent_age <= 50:
    name = "adult"

    print("adult")
else:
    name = "Senior"

    print("Senior")
for (x,y,w,h) in faces: 
        # To draw a rectangle in a face 
        font = cv2.FONT_HERSHEY_DUPLEX
      
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)
        cv2.putText(img, name, (x + 6, y - 6), font, 1.0, (0, 0, 255), 1)
        roi_gray = gray[y:y+h, x:x+w] 
        roi_color = img[y:y+h, x:x+w] 
  
        
cv2_imshow(img) 
 # Wait for Esc key to stop 
k = cv2.waitKey(30) & 0xff
#if k == 27:   
# Close the window 
# cap.release() 
  
# De-allocate any associated memory usage 
cv2.destroyAllWindows()

# def AgeDectn():

#   picture = "/content/drive/My Drive/photoshoot/IMG_4941.JPG"
#   prediction = age_model.predict(loadImage(picture))
#   apparent_age = np.round(np.sum(prediction * output_indexes, axis = 1))
#   if apparent_age <=18:
#     name = "child"
#     print("child")
#   elif 18 <= apparent_age <= 30:
#     name = "young_adult"

#     print("young_adult")
#   elif 30 <= apparent_age <= 50:
#     name = "adult"

#     print("adult")
#   else:
#     name = "Senior"

#     print("Senior")
#     #print("apparent age: ", int(apparent_age[0]))
# AgeDectn()